%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{pysmme}
\date{Mar 20, 2022}
\release{1.0}
\author{Adam Lund}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{pysmme}
\label{\detokenize{modules:pysmme}}\label{\detokenize{modules::doc}}

\section{pysmme package}
\label{\detokenize{pysmme:pysmme-package}}\label{\detokenize{pysmme::doc}}
\sphinxAtStartPar
Efficient procedure for solving the Lasso or SCAD penalized soft maximin problem.

\sphinxAtStartPar
This software implements two proximal
gradient based algorithms (NPG and FISTA) to solve two different forms of the soft
maximin problem from Lund et al., 2022 see {[}1{]} \sphinxurl{https://doi.org/10.1111/sjos.12580}:

\sphinxAtStartPar
1) For general group specific design the soft maximin problem is solved using the
NPG algorithm.

\sphinxAtStartPar
2) For fixed identical design across groups, the estimation procedure uses
either the FISTA algorithm or the NPG algorithm in the following two cases:
i) For a tensor design matrix the algorithms use array arithmetic  to
avoid the design matrix and speed computations ii) For a wavelet based design
matrix the algorithms use the pyramid algorithm to avoid the design matrix and
speed up computations.

\sphinxAtStartPar
Multi\sphinxhyphen{}threading is possible when openMP is available.


\subsection{pysmme.tools module}
\label{\detokenize{pysmme:module-pysmme.tools}}\label{\detokenize{pysmme:pysmme-tools-module}}\index{module@\spxentry{module}!pysmme.tools@\spxentry{pysmme.tools}}\index{pysmme.tools@\spxentry{pysmme.tools}!module@\spxentry{module}}
\sphinxAtStartPar
This module contains functionality for i) solving (fitting, calibratingâ€¦) the soft 
maximin problem and ii) predicting from this solution (fitted model).
\index{predict() (in module pysmme.tools)@\spxentry{predict()}\spxextra{in module pysmme.tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{pysmme:pysmme.tools.predict}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{pysmme.tools.}}\sphinxbfcode{\sphinxupquote{predict}}}{\emph{\DUrole{n}{fit}}, \emph{\DUrole{n}{x}}}{}
\sphinxAtStartPar
Make predictions from a fitted smme model.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{fit}}] \leavevmode{[}smme\_dict{]}
\sphinxAtStartPar
The output from a \sphinxcode{\sphinxupquote{pysmme.tools.softmaximin}} call

\item[{\sphinxstylestrong{x}}] \leavevmode{[}list, np.array or string{]}
\sphinxAtStartPar
An object that should be like the input to the \sphinxcode{\sphinxupquote{pysmme.tools.softmaximin}} call that 
produced the object \sphinxcode{\sphinxupquote{fit}}. For general  models a matrix
with column dimension equal to that of  the original input. 
For array models with custom design a list like the one supplied to \sphinxcode{\sphinxupquote{softmaximin}} to produce \sphinxcode{\sphinxupquote{fit}}
and for a wavelet design the name of the wavelet used to produce \sphinxcode{\sphinxupquote{fit}}.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{list}] \leavevmode
\sphinxAtStartPar
A list of length \sphinxcode{\sphinxupquote{len(zeta)}}. If \sphinxcode{\sphinxupquote{x}} is a \(k \times p\) matrix 
each list item is a \(k \times m_\zeta\) matrix containing the linear
predictors computed for each \sphinxcode{\sphinxupquote{lamb}}. If \sphinxcode{\sphinxupquote{x}} is a string or  a
list of matrices and \sphinxcode{\sphinxupquote{fit{[}"dimmodel"{]} = d}},  each list item is a \(d + 1\) array 
containing predictions computed for each \sphinxcode{\sphinxupquote{lamb}}.

\end{description}

\end{description}\end{quote}
\subsubsection*{Notes}

\sphinxAtStartPar
Given input \sphinxcode{\sphinxupquote{fit}} and \sphinxcode{\sphinxupquote{x}}, this function computes the linear predictors
using the fitted model coefficients supplied in  \sphinxcode{\sphinxupquote{fit}}  produced by  
\sphinxcode{\sphinxupquote{softmaximin}}. If \sphinxcode{\sphinxupquote{fit}} is the result of fitting general type model  
\sphinxcode{\sphinxupquote{x}} should be a \(k \times p\) matrix (\(p\) is the number of model
coefficients and \(k\) is the number of new data points). 
If \sphinxcode{\sphinxupquote{fit}} is the result of fitting a model with tensor design, \sphinxcode{\sphinxupquote{x}} should be a list containing 
\(k_i \times p_i, i = 1, 2, 3\) matrices (\(k_i\) is the number of new marginal 
data points in the \(i\) th dimension) or a string indicating the wavelet used to produce \sphinxcode{\sphinxupquote{fit}}.
\subsubsection*{Examples}

\sphinxAtStartPar
\#array data 
\#\#size of example

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{G} \PYG{o}{=} \PYG{l+m+mi}{3}\PYG{p}{;} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{n} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{65}\PYG{p}{,} \PYG{l+m+mi}{26}\PYG{p}{,} \PYG{l+m+mi}{13}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{p} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{13}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#marginal design matrices (Kronecker components)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{p}{[}\PYG{k+kc}{None}\PYG{p}{]} \PYG{o}{*} \PYG{l+m+mi}{3} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#common features and effects

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}features} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{binomial}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}sparsity of common effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}effects} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{n}{size} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{n}{common\PYGZus{}features}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#group response

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,} \PYG{n}{G}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{g} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{G}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{bg} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{l+m+mi}{1} \PYG{o}{\PYGZhy{}} \PYG{n}{common\PYGZus{}features}\PYG{p}{)} \PYG{o}{+} \PYG{n}{common\PYGZus{}effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{mu} \PYG{o}{=} \PYG{n}{RH}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,} \PYG{n}{RH}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{RH}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{n}{bg}\PYG{p}{,} \PYG{p}{(}\PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{F}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{y}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{p}{:}\PYG{p}{,} \PYG{p}{:}\PYG{p}{,} \PYG{n}{g}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n}\PYG{p}{)}\PYG{p}{)} \PYG{o}{+} \PYG{n}{mu}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#fit model for range of lambda and zeta

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{zeta} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fit} \PYG{o}{=} \PYG{n}{softmaximin}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{x}\PYG{p}{,} \PYG{n}{zeta} \PYG{o}{=} \PYG{n}{zeta}\PYG{p}{,} \PYG{n}{penalty} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lasso}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{alg} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npg}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{yhat} \PYG{o}{=} \PYG{n}{predict}\PYG{p}{(}\PYG{n}{fit}\PYG{p}{,} \PYG{n}{x}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#Array data and wavelets
\#\#size of example

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{G} \PYG{o}{=} \PYG{l+m+mi}{5}\PYG{p}{;} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{p} \PYG{o}{=} \PYG{n}{n} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#wavelet design

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{la8}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#common features and effects

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}features} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{binomial}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}sparsity of common effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}effects} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{n}{size} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{n}{common\PYGZus{}features}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#group response

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,} \PYG{n}{G}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{g} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{G}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{bg} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{l+m+mi}{1} \PYG{o}{\PYGZhy{}} \PYG{n}{common\PYGZus{}features}\PYG{p}{)} \PYG{o}{+} \PYG{n}{common\PYGZus{}effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{mu} \PYG{o}{=} \PYG{n}{iwt}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{n}{bg}\PYG{p}{,} \PYG{p}{(}\PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{F}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{y}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{p}{:}\PYG{p}{,} \PYG{p}{:}\PYG{p}{,} \PYG{n}{g}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n}\PYG{p}{)}\PYG{p}{)} \PYG{o}{+} \PYG{n}{mu}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#fit model for range of lambda and zeta

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{zeta} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fit} \PYG{o}{=} \PYG{n}{softmaximin}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{x}\PYG{p}{,} \PYG{n}{zeta} \PYG{o}{=} \PYG{n}{zeta}\PYG{p}{,} \PYG{n}{penalty} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lasso}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{alg} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npg}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{modelno} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{zetano} \PYG{o}{=} \PYG{l+m+mi}{2}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{yhat} \PYG{o}{=} \PYG{n}{predict}\PYG{p}{(}\PYG{n}{fit}\PYG{p}{,} \PYG{n}{x}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{yhat}\PYG{p}{[}\PYG{n}{zetano}\PYG{p}{]}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{p}{:}\PYG{p}{,}\PYG{p}{:}\PYG{p}{,} \PYG{n}{modelno}\PYG{p}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#Non\sphinxhyphen{}array data
\#\#size of example

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{G} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{n} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{choice}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{,}\PYG{l+m+mi}{500}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{G}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}sample(100:500, G); }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{p} \PYG{o}{=} \PYG{l+m+mi}{60}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{p}{[}\PYG{k+kc}{None}\PYG{p}{]} \PYG{o}{*} \PYG{n}{G}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#group design matrices

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#common features and effects

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}features} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{binomial}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}sparsity of common effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}effects} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{n}{size} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{n}{common\PYGZus{}features}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#group response

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y} \PYG{o}{=} \PYG{p}{[}\PYG{k+kc}{None}\PYG{p}{]} \PYG{o}{*} \PYG{n}{G}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{g} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{G}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{bg} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{l+m+mi}{1} \PYG{o}{\PYGZhy{}} \PYG{n}{common\PYGZus{}features}\PYG{p}{)} \PYG{o}{+} \PYG{n}{common\PYGZus{}effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{mu} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{matmul}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{g}\PYG{p}{]}\PYG{p}{,} \PYG{n}{bg}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{y}\PYG{p}{[}\PYG{n}{g}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{n}{g}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{n}{mu}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#fit model for range of lamb and zeta

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fit} \PYG{o}{=} \PYG{n}{softmaximin}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{x}\PYG{p}{,} \PYG{n}{zeta} \PYG{o}{=} \PYG{n}{zeta}\PYG{p}{,} \PYG{n}{penalty} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lasso}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{alg} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npg}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{yhat} \PYG{o}{=} \PYG{n}{predict}\PYG{p}{(}\PYG{n}{fit}\PYG{p}{,} \PYG{n}{x}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{softmaximin() (in module pysmme.tools)@\spxentry{softmaximin()}\spxextra{in module pysmme.tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{pysmme:pysmme.tools.softmaximin}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{pysmme.tools.}}\sphinxbfcode{\sphinxupquote{softmaximin}}}{\emph{\DUrole{n}{y}}, \emph{\DUrole{n}{x}}, \emph{\DUrole{n}{zeta}}, \emph{\DUrole{n}{penalty}}, \emph{\DUrole{n}{alg}}, \emph{\DUrole{n}{nlamb}\DUrole{o}{=}\DUrole{default_value}{30}}, \emph{\DUrole{n}{lamb\_min\_ratio}\DUrole{o}{=}\DUrole{default_value}{0.0001}}, \emph{\DUrole{n}{lamb}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{penalty\_factor}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{scale\_y}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{reltol}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}05}}, \emph{\DUrole{n}{maxiter}\DUrole{o}{=}\DUrole{default_value}{1000}}, \emph{\DUrole{n}{steps}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{btmax}\DUrole{o}{=}\DUrole{default_value}{100}}, \emph{\DUrole{n}{c}\DUrole{o}{=}\DUrole{default_value}{0.0001}}, \emph{\DUrole{n}{tau}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{M}\DUrole{o}{=}\DUrole{default_value}{4}}, \emph{\DUrole{n}{nu}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{Lmin}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{lse}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{nthreads}\DUrole{o}{=}\DUrole{default_value}{4}}}{}
\sphinxAtStartPar
Function for solving the soft maximin estimation problem
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{y}}] \leavevmode{[}list of arrays or array{]}
\sphinxAtStartPar
For a model with varying design across groups a list containing the \(G\) group specific 
response vectors of sizes \(n_i \times 1\) . For a model with identical design 
across \(G\) groups, 
an array of size \(n_1 \times\cdots\times n_d \times G\) (\(d \in \{ 1, 2, 3\}\)).

\item[{\sphinxstylestrong{x}}] \leavevmode{[}list of arrays or string{]}
\sphinxAtStartPar
For a model with varying design across groups a list containing the 
\(G\) group specific design matrices of sizes \(n_i \times p\).  
For a model with identical design across \(G\) groups, either i) a list containing the 
\(d \in \{ 1, 2, 3\}\) marginal design matrices (tensor components) or ii) 
a string indicating the type of wavelets to be used, see \sphinxcode{\sphinxupquote{pysmme.transforms.wt}} for options.

\item[{\sphinxstylestrong{zeta}}] \leavevmode{[}array of strictly positive floats{]}
\sphinxAtStartPar
Controls  the soft maximin approximation accuracy. When \sphinxcode{\sphinxupquote{len(zeta) \textgreater{} 1}} 
the procedure will distribute
the computations using the   \sphinxcode{\sphinxupquote{nthreads}} parameter below when openMP is available.

\item[{\sphinxstylestrong{penalty}}] \leavevmode{[}string{]}
\sphinxAtStartPar
Specifies the penalty type. Possible values are \sphinxcode{\sphinxupquote{lasso, scad}}.

\item[{\sphinxstylestrong{alg}}] \leavevmode{[}string{]}
\sphinxAtStartPar
Specifies the optimization algorithm. Possible values are \sphinxcode{\sphinxupquote{npg, fista}}.

\item[{\sphinxstylestrong{nlambda}}] \leavevmode{[}strictly positive int{]}
\sphinxAtStartPar
The number of \sphinxcode{\sphinxupquote{lamb}} values to use when \sphinxcode{\sphinxupquote{lamb}} is not specified.

\item[{\sphinxstylestrong{lamb\_min\_ratio}}] \leavevmode{[}strictly positive float{]}
\sphinxAtStartPar
Controls the minimum \sphinxcode{\sphinxupquote{lamb}} value by setting the ratio bewtween 
\(\lambda_{max}\) \textendash{} the (data dependent) smallest value for which all 
coefficients are zero \textendash{}  and the smallest value of \sphinxcode{\sphinxupquote{lamb}}.
Used when \sphinxcode{\sphinxupquote{lamb}} is not specified.

\item[{\sphinxstylestrong{lamb}}] \leavevmode{[}array of strictly positive floats{]}
\sphinxAtStartPar
Penalty parameters.

\item[{\sphinxstylestrong{penalty\_factor}}] \leavevmode{[}np.array{]}
\sphinxAtStartPar
Positive floats  that are multiplied with the parameters to allow for
differential penalization on the these. Same size and shape as the model 
coefficient container (array or vector).

\item[{\sphinxstylestrong{scale\_y}}] \leavevmode{[}strictly positive float{]}
\sphinxAtStartPar
Scaling factor for the response   \sphinxcode{\sphinxupquote{y}}. To temper potential overflows.

\item[{\sphinxstylestrong{reltol}}] \leavevmode{[}strictly positive float{]}
\sphinxAtStartPar
Convergence tolerance for the proximal algorithm.

\item[{\sphinxstylestrong{maxiter}}] \leavevmode{[}positive int{]}
\sphinxAtStartPar
The maximum number of  iterations
allowed for each   \sphinxcode{\sphinxupquote{lamb}} value, when  summing over all outer iterations
for said   \sphinxcode{\sphinxupquote{lamb}}.

\item[{\sphinxstylestrong{steps}}] \leavevmode{[}strictly positive int{]}
\sphinxAtStartPar
The number of steps used in the multi\sphinxhyphen{}step adaptive lasso algorithm for 
non\sphinxhyphen{}convex penalties. Automatically  set to 1 when   \sphinxcode{\sphinxupquote{penalty = "lasso"}}.

\item[{\sphinxstylestrong{btmax}}] \leavevmode{[}strictly positive integer{]}
\sphinxAtStartPar
The maximum number of backtracking steps allowed in each iteration.

\item[{\sphinxstylestrong{c}}] \leavevmode{[}strictly positive float{]}
\sphinxAtStartPar
Used in the NPG algorithm.

\item[{\sphinxstylestrong{tau}}] \leavevmode{[}strictly positive float{]}
\sphinxAtStartPar
Used to control the stepsize for NPG.

\item[{\sphinxstylestrong{M}}] \leavevmode{[}positive int{]}
\sphinxAtStartPar
The look back for the NPG.

\item[{\sphinxstylestrong{nu}}] \leavevmode{[}strictly positive float{]}
\sphinxAtStartPar
Ccontrols the stepsize in the proximal algorithm. A  value less than 1 will decrease 
the stepsize and a value larger than one will increase it.

\item[{\sphinxstylestrong{Lmin}}] \leavevmode{[}positive float{]}
\sphinxAtStartPar
Controls the stepsize in the NPG algorithm. For the default  
\sphinxcode{\sphinxupquote{Lmin = 0}} the maximum step size is the same
as for the FISTA algorithm.

\item[{\sphinxstylestrong{lse}}] \leavevmode{[}bool{]}
\sphinxAtStartPar
Indicates if log sum exp\sphinxhyphen{}loss is used.  TRUE is
default and yields the loss below.

\item[{\sphinxstylestrong{nthreads}}] \leavevmode{[}pos int{]}
\sphinxAtStartPar
The number of threads to use when  openMP  is available.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{spec}}] \leavevmode{[}string{]}
\sphinxAtStartPar
Specifications of the model fitted by the function call.

\item[{\sphinxstylestrong{coef}}] \leavevmode{[}list or np.array{]}
\sphinxAtStartPar
A \(p \times\) \sphinxcode{\sphinxupquote{nlamb}} matrix containing the
estimates of the model coefficients for each   \sphinxcode{\sphinxupquote{lamb}}\sphinxhyphen{}value
for which the procedure converged. When   \sphinxcode{\sphinxupquote{len(zeta) \textgreater{} 1}}
a   \sphinxcode{\sphinxupquote{len(zeta)}}\sphinxhyphen{}list of such matrices.

\item[{\sphinxstylestrong{lamb}}] \leavevmode{[}list or np.array{]}
\sphinxAtStartPar
The sequence of penalty values used
in the estimation procedure for which the procedure converged.
When   \sphinxcode{\sphinxupquote{len(zeta) \textgreater{} 1}} a   \sphinxcode{\sphinxupquote{len(zeta)}}\sphinxhyphen{}list of such vectors.

\item[{\sphinxstylestrong{Obj}}] \leavevmode{[}list or np.array{]}
\sphinxAtStartPar
The objective values for each
iteration and each model for which the procedure converged.
When   \sphinxcode{\sphinxupquote{len(zeta) \textgreater{} 1}} a   \sphinxcode{\sphinxupquote{len(zeta)}}\sphinxhyphen{}list of such matrices.

\item[{\sphinxstylestrong{df}}] \leavevmode{[}list or np.array{]}
\sphinxAtStartPar
Vector containing the nonzero model coefficients (degrees of freedom) for each
value of   \sphinxcode{\sphinxupquote{lamb}} for which the procedure converged. When
\sphinxcode{\sphinxupquote{len(zeta) \textgreater{} 1}} a   \sphinxcode{\sphinxupquote{len(zeta)}}\sphinxhyphen{}list of such vectors.

\item[{\sphinxstylestrong{dimcoef}}] \leavevmode{[}int or np.array{]}
\sphinxAtStartPar
Indicating the number \(p\) of model parameters.
For array data a vector giving the dimension of the model coefficient array.

\item[{\sphinxstylestrong{dimobs}}] \leavevmode{[}int or np.array{]}
\sphinxAtStartPar
The number of observations. For array data a vector giving the number of  
observations in each dimension.

\item[{\sphinxstylestrong{dimmodel}}] \leavevmode{[}int or None{]}
\sphinxAtStartPar
The dimension of the array model. \sphinxcode{\sphinxupquote{None}} for general models.

\item[{\sphinxstylestrong{diagnostics}}] \leavevmode{[}dict{]}
\sphinxAtStartPar
Key \sphinxcode{\sphinxupquote{iter}} is a vector containing the number of  iterations for each
\sphinxcode{\sphinxupquote{lamb}} value for which the algorithm converged. When \sphinxcode{\sphinxupquote{len(zeta) \textgreater{} 1}} a   
\sphinxcode{\sphinxupquote{len(zeta)}}\sphinxhyphen{}list of such vectors. Key \sphinxcode{\sphinxupquote{bt\_iter}}  is a  \sphinxcode{\sphinxupquote{len(zeta)}} vector
with total number of backtracking steps performed across all (converged) \sphinxcode{\sphinxupquote{lamb}} values 
for given \sphinxcode{\sphinxupquote{zeta}} value. Key \sphinxcode{\sphinxupquote{bt\_enter}} is a  \sphinxcode{\sphinxupquote{len(zeta)}} vector
with total number of times backtracking is initiated across all (converged) \sphinxcode{\sphinxupquote{lamb}} values 
for given \sphinxcode{\sphinxupquote{zeta}} value.

\end{description}

\end{description}\end{quote}
\subsubsection*{Notes}

\sphinxAtStartPar
Consider modeling heterogeneous data \(\{y_1,\ldots, y_n\}\) by dividing
it into \(G\) groups \(\mathbf{y}_g = (y_1, \ldots, y_{n_g})\) ,
\(g \in \{ 1,\ldots, G\}\) and then using a linear model
\begin{equation*}
\begin{split}\mathbf{y}_g = \mathbf{X}_gb_g + \epsilon_g, \  g \in \{1,\ldots, G\},\end{split}
\end{equation*}
\sphinxAtStartPar
to model the group response. Then \(b_g\) is a group specific \(p\times 1\)
coefficient vector, \(\mathbf{X}_g\) an \(n_g\times p\) group design matrix and
\(\epsilon_g\) an \(n_g\times 1\) error term. The objective is to estimate
a common coefficient \(\beta\) such that \(\mathbf{X}_g\beta\) is a robust
and good approximation to \(\mathbf{X}_gb_g\) across groups.

\sphinxAtStartPar
Following \sphinxcite{pysmme:r1b89a25bbb8d-1}, this objective may be accomplished by
solving the soft maximin estimation problem
\begin{equation*}
\begin{split}\min_{\beta}\frac{1}{\zeta}\log\bigg(\sum_{g = 1}^G \exp(-\zeta \hat V_g(\beta))\bigg) + \lambda  \Vert\beta\Vert_1, \quad \zeta > 0,\lambda \geq 0.\end{split}
\end{equation*}
\sphinxAtStartPar
Here \(\zeta\) essentially controls the amount of pooling across groups
(\(\zeta \sim 0\) effectively ignores grouping and pools observations) and
\begin{equation*}
\begin{split}\hat V_g(\beta):=\frac{1}{n_g}(2\beta^\top \mathbf{X}_g^\top \mathbf{y}_g -\beta^\top \mathbf{X}_g^\top \mathbf{X}_g\beta),\end{split}
\end{equation*}
\sphinxAtStartPar
is the empirical explained variance, see \sphinxcite{pysmme:r1b89a25bbb8d-1} for more
details and references.

\sphinxAtStartPar
The function  \sphinxcode{\sphinxupquote{softmaximin}} solves the soft maximin estimation problem in
large scale settings for a sequence of penalty parameters
\(\lambda_{max}>\ldots >\lambda_{min}>0\) and a sequence of strictly positive
softmaximin  parameters \(\zeta_1, \zeta_2,\ldots\).

\sphinxAtStartPar
The implementation also solves the
problem above with the penalty given by the SCAD penalty, using the multiple
step adaptive lasso procedure to loop over the inner proximal algorithm.

\sphinxAtStartPar
Two optimization algorithms  are implemented in the SMME packages;
a non\sphinxhyphen{}monotone proximal gradient (NPG) algorithm and a fast iterative soft
thresholding algorithm (FISTA).

\sphinxAtStartPar
The implementation is particularly efficient for models where the design is
identical across groups i.e. \(\mathbf{X}_g = \mathbf{X}\)
\(\forall g \in \{1, \ldots, G\}\) in the following two cases:

\sphinxAtStartPar
i) first if \(\mathbf{X}\) has Kronecker (tensor) structure i.e. for marginal \(n_i\times p_i\) design matrices \(\mathbf{M}_1,\ldots, \mathbf{M}_d\)
, \(d \in \{ 1, 2, 3\}\),
\begin{equation*}
\begin{split}\mathbf{X} = \bigotimes_{i=1}^d \mathbf{M}_i \end{split}
\end{equation*}
\sphinxAtStartPar
then \sphinxcode{\sphinxupquote{y}} is a \(d + 1\) dimensional response array
and    \sphinxcode{\sphinxupquote{x}} is a list containing the \(d\) marginal matrices
\(\mathbf{M}_1,\ldots, \mathbf{M}_d\). In this case  softmaximin solves
the soft maximin problem using minimal memory by way of tensor optimized
arithmetic, see also   \sphinxcode{\sphinxupquote{RH}}.

\sphinxAtStartPar
ii) second, if the design matrix \(\mathbf{X}\) is the inverse matrix of an
orthogonal wavelet transform  then \sphinxcode{\sphinxupquote{softmaximin}}  will solve the soft maximin 
problem given  \sphinxcode{\sphinxupquote{x = str}} \textendash{} where \sphinxcode{\sphinxupquote{str}} is a shorthand for the wavelet basis (seeâ€¦.) \textendash{} and 
the \(d + 1\) dimensional response array  \sphinxcode{\sphinxupquote{y}}. In this case  the  pyramid algorithm is used 
to compute multiplications involving \(\mathbf{X}\).

\sphinxAtStartPar
Note that when multiple values for \(\zeta\) is provided it is  possible to
distribute the computations across CPUs if openMP is available.
\subsubsection*{References}

\sphinxAtStartPar
\sphinxcite{pysmme:r1b89a25bbb8d-1}
\subsubsection*{Examples}

\sphinxAtStartPar
\#Non\sphinxhyphen{}array data \#\#size of example

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{G} \PYG{o}{=} \PYG{l+m+mi}{3}\PYG{p}{;} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{n} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{65}\PYG{p}{,} \PYG{l+m+mi}{26}\PYG{p}{,} \PYG{l+m+mi}{13}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{p} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{13}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#marginal design matrices (Kronecker components)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{p}{[}\PYG{k+kc}{None}\PYG{p}{]} \PYG{o}{*} \PYG{l+m+mi}{3} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#common features and effects

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}features} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{binomial}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}sparsity of common effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}effects} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{n}{size} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{n}{common\PYGZus{}features}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#group response

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,} \PYG{n}{G}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{g} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{G}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{bg} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{l+m+mi}{1} \PYG{o}{\PYGZhy{}} \PYG{n}{common\PYGZus{}features}\PYG{p}{)} \PYG{o}{+} \PYG{n}{common\PYGZus{}effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{mu} \PYG{o}{=} \PYG{n}{RH}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,} \PYG{n}{RH}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{RH}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{n}{bg}\PYG{p}{,} \PYG{p}{(}\PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{F}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{y}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{p}{:}\PYG{p}{,} \PYG{p}{:}\PYG{p}{,} \PYG{n}{g}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n}\PYG{p}{)}\PYG{p}{)} \PYG{o}{+} \PYG{n}{mu}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#fit model for range of lambda and zeta

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{zeta} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fit} \PYG{o}{=} \PYG{n}{softmaximin}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{x}\PYG{p}{,} \PYG{n}{zeta} \PYG{o}{=} \PYG{n}{zeta}\PYG{p}{,} \PYG{n}{penalty} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lasso}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{alg} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npg}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{modelno} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{zetano} \PYG{o}{=} \PYG{l+m+mi}{2}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{betahat} \PYG{o}{=} \PYG{n}{fit}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{coef}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{zetano}\PYG{p}{]}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{n}{modelno}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{f}\PYG{p}{,} \PYG{n}{ax} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{common\PYGZus{}effects}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{r+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{betahat}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\sphinxAtStartPar
\#Array data and wavelets
\#\#size of example

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{set}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{42}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{G} \PYG{o}{=} \PYG{l+m+mi}{5}\PYG{p}{;} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{p} \PYG{o}{=} \PYG{n}{n} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#common features and effects

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}features} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{binomial}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}sparsity of common effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}effects} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{n}{size} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{n}{common\PYGZus{}features}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#group response

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,} \PYG{n}{G}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{g} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{G}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{bg} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{l+m+mi}{1} \PYG{o}{\PYGZhy{}} \PYG{n}{common\PYGZus{}features}\PYG{p}{)} \PYG{o}{+} \PYG{n}{common\PYGZus{}effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{mu} \PYG{o}{=} \PYG{n}{iwt}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{n}{bg}\PYG{p}{,} \PYG{p}{(}\PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{F}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{y}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{p}{:}\PYG{p}{,} \PYG{p}{:}\PYG{p}{,} \PYG{n}{g}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n}\PYG{p}{)}\PYG{p}{)} \PYG{o}{+} \PYG{n}{mu}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#fit model for range of lambda and zeta

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{zeta} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fit} \PYG{o}{=} \PYG{n}{softmaximin}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{x}\PYG{p}{,} \PYG{n}{zeta} \PYG{o}{=} \PYG{n}{zeta}\PYG{p}{,} \PYG{n}{penalty} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lasso}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{alg} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npg}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{modelno} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{zetano} \PYG{o}{=} \PYG{l+m+mi}{2}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{betahat} \PYG{o}{=} \PYG{n}{fit}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{coef}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{zetano}\PYG{p}{]}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{n}{modelno}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{f}\PYG{p}{,} \PYG{n}{ax} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{common\PYGZus{}effects}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{r+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{betahat}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#Non\sphinxhyphen{}array data
\#\#size of example

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{G} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{n} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{choice}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{,}\PYG{l+m+mi}{500}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{G}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}sample(100:500, G); }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{p} \PYG{o}{=} \PYG{l+m+mi}{60}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{p}{[}\PYG{k+kc}{None}\PYG{p}{]} \PYG{o}{*} \PYG{n}{G}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#group design matrices

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{p}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#common features and effects

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}features} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{binomial}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}sparsity of common effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{common\PYGZus{}effects} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{n}{size} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{n}{common\PYGZus{}features}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#group response

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y} \PYG{o}{=} \PYG{p}{[}\PYG{k+kc}{None}\PYG{p}{]} \PYG{o}{*} \PYG{n}{G}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{g} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{G}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{bg} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{prod}\PYG{p}{(}\PYG{n}{p}\PYG{p}{)}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{l+m+mi}{1} \PYG{o}{\PYGZhy{}} \PYG{n}{common\PYGZus{}features}\PYG{p}{)} \PYG{o}{+} \PYG{n}{common\PYGZus{}effects}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{mu} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{matmul}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{g}\PYG{p}{]}\PYG{p}{,} \PYG{n}{bg}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{y}\PYG{p}{[}\PYG{n}{g}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{n}\PYG{p}{[}\PYG{n}{g}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{n}{mu}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#fit model for range of lamb and zeta

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fit} \PYG{o}{=} \PYG{n}{softmaximin}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{x}\PYG{p}{,} \PYG{n}{zeta} \PYG{o}{=} \PYG{n}{zeta}\PYG{p}{,} \PYG{n}{penalty} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lasso}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{alg} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npg}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{betahat} \PYG{o}{=} \PYG{n}{fit}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{coef}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#estimated common effects for specific lamb and zeta

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{modelno} \PYG{o}{=} \PYG{l+m+mi}{6} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{zetano} \PYG{o}{=} \PYG{l+m+mi}{2}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{f}\PYG{p}{,} \PYG{n}{ax} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{common\PYGZus{}effects}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{r+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{betahat}\PYG{p}{[}\PYG{n}{zetano}\PYG{p}{]}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{n}{modelno}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\end{fulllineitems}



\subsection{pysmme.transforms module}
\label{\detokenize{pysmme:module-pysmme.transforms}}\label{\detokenize{pysmme:pysmme-transforms-module}}\index{module@\spxentry{module}!pysmme.transforms@\spxentry{pysmme.transforms}}\index{pysmme.transforms@\spxentry{pysmme.transforms}!module@\spxentry{module}}
\sphinxAtStartPar
This module contains various transforms for computing fast matrix vector products in specific situations.
\index{H() (in module pysmme.transforms)@\spxentry{H()}\spxextra{in module pysmme.transforms}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{pysmme:pysmme.transforms.H}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{pysmme.transforms.}}\sphinxbfcode{\sphinxupquote{H}}}{\emph{\DUrole{n}{M}}, \emph{\DUrole{n}{A}}}{}
\end{fulllineitems}

\index{RH() (in module pysmme.transforms)@\spxentry{RH()}\spxextra{in module pysmme.transforms}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{pysmme:pysmme.transforms.RH}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{pysmme.transforms.}}\sphinxbfcode{\sphinxupquote{RH}}}{\emph{\DUrole{n}{M}}, \emph{\DUrole{n}{A}}}{}
\sphinxAtStartPar
The Rotated H\sphinxhyphen{}transform of a 3d Array by a Matrix.

\sphinxAtStartPar
This function is an implementation of the \(\rho\)\sphinxhyphen{}operator found in
(Currie et al, 2006). It forms the basis of the GLAM arithmetic.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{M}}] \leavevmode{[}np.array{]}
\sphinxAtStartPar
A \(n \times p_1\) matrix.

\item[{\sphinxstylestrong{A}}] \leavevmode{[}np.array{]}
\sphinxAtStartPar
A 3d array of size \(p_1 \times p_2 \times p_3\).

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{np.array}] \leavevmode
\sphinxAtStartPar
A 3d array of size \(p_2 \times p_3 \times n\).

\end{description}

\end{description}\end{quote}
\subsubsection*{Notes}

\sphinxAtStartPar
For details see (Currie et al, 2006) \sphinxcite{pysmme:r37e8b8eec84f-2}. Note that this particular implementation
is not used in the  routines underlying the optimization procedure.
\subsubsection*{References}

\sphinxAtStartPar
\sphinxcite{pysmme:r37e8b8eec84f-2}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{n1} \PYG{o}{=} \PYG{l+m+mi}{15}\PYG{p}{;} \PYG{n}{n2} \PYG{o}{=} \PYG{l+m+mi}{4}\PYG{p}{;} \PYG{n}{n3} \PYG{o}{=} \PYG{l+m+mi}{3}\PYG{p}{;} \PYG{n}{p1} \PYG{o}{=} \PYG{l+m+mi}{12}\PYG{p}{;} \PYG{n}{p2} \PYG{o}{=} \PYG{l+m+mi}{3}\PYG{p}{;} \PYG{n}{p3} \PYG{o}{=} \PYG{l+m+mi}{4}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}marginal design matrices (Kronecker components)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{X1} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n1}\PYG{p}{,} \PYG{n}{p1}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{X2} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n2}\PYG{p}{,} \PYG{n}{p2}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{X3} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{n3}\PYG{p}{,} \PYG{n}{p3}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{A} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{p}{(}\PYG{n}{p1}\PYG{p}{,} \PYG{n}{p2}\PYG{p}{,} \PYG{n}{p3}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{R1} \PYG{o}{=} \PYG{n}{RH}\PYG{p}{(}\PYG{n}{X3}\PYG{p}{,} \PYG{n}{RH}\PYG{p}{(}\PYG{n}{X2}\PYG{p}{,} \PYG{n}{RH}\PYG{p}{(}\PYG{n}{X1}\PYG{p}{,} \PYG{n}{A}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{R2} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{matmul}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{kron}\PYG{p}{(}\PYG{n}{X3}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{kron}\PYG{p}{(}\PYG{n}{X2}\PYG{p}{,} \PYG{n}{X1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{n}{A}\PYG{p}{,} \PYG{p}{[}\PYG{n}{p1} \PYG{o}{*} \PYG{n}{p2} \PYG{o}{*} \PYG{n}{p3}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{F}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{max}\PYG{p}{(}\PYG{n+nb}{abs}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{n}{R1}\PYG{p}{,} \PYG{p}{[}\PYG{n}{n1} \PYG{o}{*} \PYG{n}{n2} \PYG{o}{*} \PYG{n}{n3}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{F}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{R2}\PYG{p}{)}\PYG{p}{)} 
\end{sphinxVerbatim}

\end{fulllineitems}

\index{Rotate() (in module pysmme.transforms)@\spxentry{Rotate()}\spxextra{in module pysmme.transforms}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{pysmme:pysmme.transforms.Rotate}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{pysmme.transforms.}}\sphinxbfcode{\sphinxupquote{Rotate}}}{\emph{\DUrole{n}{A}}}{}
\end{fulllineitems}

\index{iwt() (in module pysmme.transforms)@\spxentry{iwt()}\spxextra{in module pysmme.transforms}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{pysmme:pysmme.transforms.iwt}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{pysmme.transforms.}}\sphinxbfcode{\sphinxupquote{iwt}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{wf}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}la8\textquotesingle{}}}, \emph{\DUrole{n}{J}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Discrete inverse wavelet transform.

\sphinxAtStartPar
This function performs a level J wavelet transform of a dyadic input array (1d, 2d, or 3d) 
using the pyramid algorithm (Mallat 1989). Implemented in C by Brandon Whithcer.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{x}}] \leavevmode{[}np.array{]}
\sphinxAtStartPar
A 1, 2, or 3 dimensional data array. The size of each dimension must be dyadic.

\item[{\sphinxstylestrong{wf}}] \leavevmode{[}string{]}
\sphinxAtStartPar
The type of wavelet family used. Options are \sphinxcode{\sphinxupquote{"haar", "d4", "??","mb4","fk4","d6","fk6", 
"d8","fk8", "la8","mb8","bl14","fk14", "d16","la16","mb16", "la20","bl20","fk22", "mb24"}}

\item[{\sphinxstylestrong{J}}] \leavevmode{[}int{]}
\sphinxAtStartPar
The level (depth) of the decomposition. For default \sphinxcode{\sphinxupquote{None}} the max
depth is used and  \sphinxcode{\sphinxupquote{wt(x)}} is equal to multiplying \sphinxcode{\sphinxupquote{x}} with the
corresponding inverse wavelet transform matrix.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{np.array}] \leavevmode
\sphinxAtStartPar
Array with shape identical to input \sphinxcode{\sphinxupquote{x}} containing the transform values.

\end{description}

\end{description}\end{quote}
\subsubsection*{Notes}

\sphinxAtStartPar
This is a C++/Python wrapper function for a C implementation of the
discrete inverse wavelet transform. Given a data array (1d, 2d or 3d) with dyadic
dimensions sizes this transform is computed efficiently via the pyramid
algorithm using C routines from  Brandon Whitcherâ€™s Waveslim package for R, see
Percival and Walden (2000); Gencay, Selcuk and Whitcher (2001).

\sphinxAtStartPar
This functionality is used in the computations underlying \sphinxcode{\sphinxupquote{softmaximin}}
to perform multiplications involving the wavelet (design) matrix efficiently.

\end{fulllineitems}

\index{wt() (in module pysmme.transforms)@\spxentry{wt()}\spxextra{in module pysmme.transforms}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{pysmme:pysmme.transforms.wt}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{pysmme.transforms.}}\sphinxbfcode{\sphinxupquote{wt}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{wf}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}la8\textquotesingle{}}}, \emph{\DUrole{n}{J}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Discrete wavelet transform.

\sphinxAtStartPar
This function performs a level J wavelet transform of the input array (1d, 2d, or 3d) 
using the pyramid algorithm (Mallat 1989). Implemented in C by Brandon Whithcer.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{x}}] \leavevmode{[}np.array{]}
\sphinxAtStartPar
A 1, 2, or 3 dimensional data array. The size of each dimension must be dyadic.

\item[{\sphinxstylestrong{wf}}] \leavevmode{[}string{]}
\sphinxAtStartPar
The type of wavelet family used. Options are 
\sphinxcode{\sphinxupquote{"haar", "d4", "??","mb4","fk4","d6","fk6", "d8","fk8", "la8","mb8","bl14","fk14", "d16","la16","mb16", "la20","bl20","fk22", "mb24"}}

\item[{\sphinxstylestrong{J}}] \leavevmode{[}int{]}
\sphinxAtStartPar
J is the level (depth) of the decomposition. For default None the max
depth is used and  \sphinxcode{\sphinxupquote{wt(x)}} is equal to multiplying \sphinxcode{\sphinxupquote{x}} with the
corresponding wavelet matrix.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{np.array}] \leavevmode
\sphinxAtStartPar
Array with shape identical to input \sphinxcode{\sphinxupquote{x}} containing the transform values.

\end{description}

\end{description}\end{quote}
\subsubsection*{Notes}

\sphinxAtStartPar
This is a C++/Python wrapper function for a C implementation of the
discrete wavelet transform. Given a data array (1d, 2d or 3d) with dyadic
dimensions sizes this transform is computed efficiently via the pyramid
algorithm using C routines from  Brandon Whitcherâ€™s Waveslim package for R, see
Percival and Walden (2000) ; Gencay, Selcuk and Whitcher (2001).

\sphinxAtStartPar
This functionality is used in the computations underlying \sphinxcode{\sphinxupquote{pysmme.tools.softmaximin}}
to perform multiplications involving the wavelet (design) matrix efficiently.
\subsubsection*{References}

\sphinxAtStartPar
\sphinxcite{pysmme:rf3008b54b32e-3}, \sphinxcite{pysmme:rf3008b54b32e-4}, \sphinxcite{pysmme:rf3008b54b32e-5}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{d} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{3} \PYG{o}{+} \PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{,} \PYG{n}{order} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{F}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{d1} \PYG{o}{=} \PYG{n}{wt}\PYG{p}{(}\PYG{n}{d}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{d2} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{p}{[} \PYG{l+m+mf}{1.41421356e+00}\PYG{p}{,}  \PYG{l+m+mf}{4.16333634e\PYGZhy{}17}\PYG{p}{]}\PYG{p}{,}
\PYG{g+go}{     [ 5.65685425e+00, \PYGZhy{}3.33644647e\PYGZhy{}16]],}
\PYG{g+go}{    [[ 2.82842712e+00, \PYGZhy{}2.77555756e\PYGZhy{}17],}
\PYG{g+go}{     [\PYGZhy{}2.64953102e\PYGZhy{}16,  1.27279221e+01]]])}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iwt}\PYG{p}{(}\PYG{n}{d2}\PYG{p}{)}     
\end{sphinxVerbatim}

\end{fulllineitems}



\subsection{Module contents}
\label{\detokenize{pysmme:module-pysmme}}\label{\detokenize{pysmme:module-contents}}\index{module@\spxentry{module}!pysmme@\spxentry{pysmme}}\index{pysmme@\spxentry{pysmme}!module@\spxentry{module}}
\sphinxAtStartPar
Root module of your package


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{search}

\end{itemize}

\begin{sphinxthebibliography}{1}
\bibitem[1]{pysmme:r1b89a25bbb8d-1}
\sphinxAtStartPar
Lund, A., S. W. Mogensen and N. R. Hansen (2022). Soft Maximin Estimation for
Heterogeneous Data. Scandinavian Journal of Statistics. url = \sphinxurl{https://doi.org/10.1111/sjos.12580}
\bibitem[2]{pysmme:r37e8b8eec84f-2}
\sphinxAtStartPar
Currie, I. D., M. Durban, and P. H. C. Eilers (2006). Generalized linear
array models with applications to multidimensional smoothing.
Journal of the Royal Statistical Society. Series B. 68, 
259\sphinxhyphen{}280. url = \sphinxurl{http://dx.doi.org/10.1111/j.1467-9868.2006.00543.x}.
\bibitem[3]{pysmme:rf3008b54b32e-3}
\sphinxAtStartPar
Gencay, R., F. Selcuk and B. Whitcher (2001) An Introduction to Wavelets and
Other Filtering Methods in Finance and Economics, Academic Press.
\bibitem[4]{pysmme:rf3008b54b32e-4}
\sphinxAtStartPar
Mallat, S. G. (1989) A theory for multiresolution signal decomposition: the
wavelet representation, IEEE Transactions on Pattern Analysis and Machine
Intelligence, 11, No. 7, 674\sphinxhyphen{}693.
\bibitem[5]{pysmme:rf3008b54b32e-5}
\sphinxAtStartPar
Percival, D. B. and A. T. Walden (2000) Wavelet Methods for Time Series
Analysis, Cambridge University Press.
\end{sphinxthebibliography}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{p}
\item\relax\sphinxstyleindexentry{pysmme}\sphinxstyleindexpageref{pysmme:\detokenize{module-pysmme}}
\item\relax\sphinxstyleindexentry{pysmme.tools}\sphinxstyleindexpageref{pysmme:\detokenize{module-pysmme.tools}}
\item\relax\sphinxstyleindexentry{pysmme.transforms}\sphinxstyleindexpageref{pysmme:\detokenize{module-pysmme.transforms}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}